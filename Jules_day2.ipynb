{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-Sch-O/EI-WebSearch/blob/main/Jules_day2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiy0xFlZLomY"
      },
      "source": [
        "# Web Information Retrieval\n",
        "## Introduction to search engines\n",
        "\n",
        "### DAY 2: Teacher version\n",
        "### Implementing a search engine\n",
        "\n",
        "The goal of this second session is to implement a first architecture of a search engine on the previously introduced dataset (stackexchange-datascience). If you missed the first session or if you did not saved the dataset, please reload the first session's notebook to download it. \n",
        "\n",
        "If you need some ifnormation about the dataset, it should be available here : https://archive.org/details/stackexchange\n",
        "\n",
        "The notebook is divided into several steps:\n",
        "-\tImplement the indexation\n",
        "-\tImplement the search method\n",
        "-\tDefine a ranking strategy and implement it\n",
        "-\tSuggest some improvements of the search engine\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH_WrILaSIJL"
      },
      "source": [
        "## Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H819R7iJF_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e340fd-b1fc-41f7-a734-5376a1df616d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ttable\n",
            "  Downloading ttable-0.6.4.tar.gz (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ttable\n",
            "  Building wheel for ttable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ttable: filename=ttable-0.6.4-cp310-cp310-linux_x86_64.whl size=212625 sha256=b6297a4d5f537f4debb1a98a4a5838711bf0a0bd6482696a63bf774b1ddb4f47\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/8d/56/f2572fdbf1ef1f8a947d7ff25ce18d9373d8e02a68f9ac8de6\n",
            "Successfully built ttable\n",
            "Installing collected packages: ttable\n",
            "Successfully installed ttable-0.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ttable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lI2VFiG1SJmJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from itertools import product\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "AK-fo8Do85hw",
        "outputId": "07bd1736-017f-4583-d142-93e359730905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YySiGfQ1SNwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a252fdcd-a931-4e0f-a604-ef2135b76a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0rq6fLsSSPUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d82d8a7-d2bb-42fe-ecbd-78b6f6738478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/EI_ST4/data\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/drive/MyDrive/EI_ST4/data' \n",
        "print(DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kiMuicy6Du8"
      },
      "source": [
        "**Important :**\n",
        "\n",
        "An Excel file for testing the evaluation part is available in the gitlab repo : evaluation_search_engine_post_queries_ranking_EI_CS.xlsx\n",
        "\n",
        "If you work on Colab, we advice you to push it directly on your Google Drive directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzqYFBxYAJN1"
      },
      "source": [
        "# Implement the indexation\n",
        "As you might already know, for a search engine to work properly an index of the documents must be created. Here we will keep it in python, and try to use only common libraries to keep it simple.\n",
        "\n",
        "Once created, the index will be used to match the query with the documents. As a result, there are several ways to build an index, using statistical, boolean, semantic indexation...\n",
        "\n",
        "First of, let's make a naive one that will consist in breaking down each document into a set of the words it contains."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tX5rDdNE63j",
        "outputId": "62010251-9722-47f5-9e86-4d00c8b5f7e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrBhrbBBN7sx",
        "outputId": "0a387481-507c-4219-8af0-697695beb911"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lOClVNL5_abL"
      },
      "outputs": [],
      "source": [
        "\"\"\"from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def extract_words(text:str)->list:\n",
        "  # 2. On extrait les mots et les nombres\n",
        "  tokenizer = RegexpTokenizer('[a-zA-Z]{2,}|\\d+\\S?\\d*')\n",
        "  wordtokens = tokenizer.tokenize(text)\n",
        "\n",
        "  return text\n",
        "\"\"\"\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import AutoTokenizer\n",
        "def extract_words(text):\n",
        "  RES=[] #liste des termes qui seront ensuite lemmatisés\n",
        "\n",
        "  if len(text)==0:\n",
        "    pass\n",
        "  else:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenizer=AutoTokenizer.from_pretrained('bert-base-cased') \n",
        "    res=tokenizer.tokenize(text) #liste de mots tokenizé\n",
        "    for x in res:\n",
        "      y=lemmatizer.lemmatize(x)\n",
        "      RES.append(y)\n",
        "    \n",
        "  \n",
        "  return RES\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_words(\"I would like to have a swimming pool\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sculMGgHBwUT",
        "outputId": "d381baa4-3aac-4bc7-d574-5e6ff4813d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'would', 'like', 'to', 'have', 'a', 'swimming', 'pool']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwVgveW6CIAz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# test\n",
        "s = \"The cat is sat on the mat. The dog is laid on the mat.\"\n",
        "assert extract_words(s).sort()==[\"The\",\"cat\",\"is\",\"sat\",\"on\",\"the\",\"mat.\",\"dog\",\"laid\"].sort()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWI8SX7bHxyc",
        "outputId": "9048db13-fd06-4385-b412-4973b525f7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTFNPmNJC75C"
      },
      "source": [
        "As you may notice, there are several problems with the previous implementation. First, \"The\" and \"the\" aren't considered the same, the \".\" is kept at the the end of \"mat.\" as any other punctuation character... \n",
        "\n",
        "Re-implement this function with some basic preprocessing to avoid these issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg9aRYX-CTTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnTSVCA1Fd1q"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "assert extract_words(s).sort()==[\"the\",\"cat\",\"is\",\"sat\",\"on\",\"mat\",\"dog\",\"laid\"].sort()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVQq7QZKF7mM"
      },
      "source": [
        "Now you sould be able to create your index table. For now we will just make a dataframe with two columns: [raw_text, words]."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQd7Hu9GR60L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpK3zlftGw_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "84aa75f3-6cc3-4724-a146-852fc15a204b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on va extraire\n",
            "The cat is sat on the mat. The dog is laid on the mat.\n",
            "------\n",
            "on va extraire\n",
            "Hello World!\n",
            "------\n",
            "on va extraire\n",
            "Goodbye\n",
            "------\n",
            "on va extraire\n",
            "How are you?\n",
            "------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            raw_text  \\\n",
              "0  The cat is sat on the mat. The dog is laid on ...   \n",
              "1                                       Hello World!   \n",
              "2                                            Goodbye   \n",
              "3                                       How are you?   \n",
              "\n",
              "                                               words  \n",
              "0  [The, cat, is, sat, on, the, mat, ., The, dog,...  \n",
              "1                                  [Hello, World, !]  \n",
              "2                                          [Goodbye]  \n",
              "3                                 [How, are, you, ?]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af5dbf9e-ccac-4430-b305-b35cdc2804af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_text</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The cat is sat on the mat. The dog is laid on ...</td>\n",
              "      <td>[The, cat, is, sat, on, the, mat, ., The, dog,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hello World!</td>\n",
              "      <td>[Hello, World, !]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Goodbye</td>\n",
              "      <td>[Goodbye]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How are you?</td>\n",
              "      <td>[How, are, you, ?]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5dbf9e-ccac-4430-b305-b35cdc2804af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af5dbf9e-ccac-4430-b305-b35cdc2804af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af5dbf9e-ccac-4430-b305-b35cdc2804af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# test\n",
        "\n",
        "L = [s, \"Hello World!\", \"Goodbye\", \"How are you?\"]\n",
        "\n",
        "index_docs(L)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.join(DATA_PATH, 'Posts.xml'))"
      ],
      "metadata": {
        "id": "D8MLmCh4Viv3",
        "outputId": "68d6ad22-7a69-4ca3-a49f-246ae5318f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EI_ST4/data/Posts.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70w-UfpsHktY"
      },
      "source": [
        "Now, let's try it on the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46pO8FszG_4s"
      },
      "outputs": [],
      "source": [
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcaGAngHLK4g"
      },
      "source": [
        "For our first version of the indexation mechanism, we will simply use the \"body\" of the posts. To have a better search engine, the title and other metadata aswell could be used aswell. Finally, not all the XML files have a \"body\" feature, so for the search engine to retrieve information from any of the files you will need to implement another way to index.\n",
        "\n",
        "But first, let's start with \"body\". There is more to preprocess than before, indeed, there are html tags such as \"<p>\" for instance. They are not useful for us, because users won't use them in their queries. So we first need to remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et-7VlXyKuaf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "def remove_tags(text:str)->str:\n",
        "  # TODO\n",
        "  clean_text = text.replace('\\n', ' ')\n",
        "  #clean_text = ' '.join(c_text.split())\n",
        "\n",
        "\n",
        "  pattern = re.compile('<.*?>')\n",
        "\n",
        "\n",
        "  result = re.sub(pattern, '', clean_text)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQAW9pi9MkyZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea99493f-bca1-4ebb-d843-83be8ba2297a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello World! I am making a search engine.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# test\n",
        "remove_tags('<p>Hello World!\\nI am making a search engine.<p>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDiFEsPtMszw"
      },
      "outputs": [],
      "source": [
        "clean_posts = posts[['Id','Body']]\n",
        "clean_posts['Clean Body'] = clean_posts['Body'].fillna('').apply(remove_tags)\n",
        "clean_posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RbkcTyrNDcJ"
      },
      "outputs": [],
      "source": [
        "clean_posts['words'] = clean_posts['Clean Body'].apply(extract_words)\n",
        "clean_posts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWfNgdg7ziCm"
      },
      "source": [
        "## Zipf Law\n",
        "\n",
        "A way of analyzing a corpus is to draw the zipf law"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrts6RVNziLk"
      },
      "outputs": [],
      "source": [
        "# TODO : Draw Zipf Law on the Posts Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOYd2qLpwhHE"
      },
      "source": [
        "## Inverted Index\n",
        "\n",
        "Now, we want to go further on the indexing and build an inverted index. Inverted index is a dictionary where the keys are the words of the vocabulary and the values are the documents containing these words. Reducing the size of the vocabulary is a relevant first step when building an inverted index. Here, we will focus on the creation of the index, we leave you the optimisation steps :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLO7naGaF0LP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def index_docs(docs:list[str])->pd.DataFrame:\n",
        "  df=pd.DataFrame()\n",
        "  phrases=[]\n",
        "  Mots=[]\n",
        "\n",
        "  for p in L:\n",
        "    print('on va extraire')\n",
        "    mots=extract_words(p)\n",
        "    print(p)\n",
        "    print('------')\n",
        "    phrases.append(p)\n",
        "    Mots.append(mots)\n",
        "  df['raw_text']=phrases\n",
        "  df['words']=Mots\n",
        "  print(Mots)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def create_index(posts:pd.DataFrame)-> set: #on suppose posts déjà traité\n",
        "  inv_ind = {}\n",
        "  for i in range(len(posts['Id'])):\n",
        "    words = posts['words'][i]; id = posts['Id'][i]#liste des mots du doc i ; \n",
        "    for word in words:\n",
        "      if word in inv_ind:\n",
        "        inv_ind[word] += [id]\n",
        "      else:\n",
        "        inv_ind[word] = [id]\n",
        "  return inv_ind"
      ],
      "metadata": {
        "id": "m4gGPmrKtw3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCPc3tRMZj9R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "2693a693-34ed-49e6-cde2-8b81c5f2cbb3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-85edcf1b519e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minverted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_posts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'clean_posts' is not defined"
          ]
        }
      ],
      "source": [
        "inverted_index = create_index(clean_posts.iloc[0:5000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q97D2TjBOVZP"
      },
      "source": [
        "#### Well Done, you've indexed the dataset! \n",
        "Don't hesitate to save your indexes in txt or pickle file\n",
        "\n",
        "---\n",
        "# Implement the search method\n",
        "\n",
        "A naive method would be to count the number of words in common between the query and each posts. Then to rank the posts you could directly select the post who maximize the number of common words. Let's implement this approach :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZX8J3Vrq7St"
      },
      "outputs": [],
      "source": [
        "# Implement the word_in_index function \n",
        "# Inputs : a word (str) & a list of words\n",
        "# Output : pandas series of 1 if the word is in the list, else 0\n",
        "\n",
        "def word_in_index(word, word_list_index):\n",
        "  # TODO\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFvxO88LtVi8"
      },
      "outputs": [],
      "source": [
        "# Implement the function which run through a pandas series and count the number of word in common\n",
        "# Use extract_words method, apply method with word_in_index function\n",
        "# Inputs : the query (str) & pandas series of strings\n",
        "# Output : Pandas series counting the number of common words between the query and each string in word_serie\n",
        "\n",
        "def count_common_words(query, word_serie):\n",
        "  # TODO\n",
        "  \n",
        "  return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHzyXeExNWQq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rank_top_query(query, df, top=5):\n",
        "  # TODO\n",
        "\n",
        "\n",
        "  return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRdErltStZGv"
      },
      "outputs": [],
      "source": [
        "rank_top_query(query=\"testing the query in python\", df=clean_posts, top=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JumHiP3txgUb"
      },
      "source": [
        "Testez plusieurs requêtes et critiquez les résultats obtenus.\n",
        "\n",
        "Quels sont les pros and cons de cette méthodes. Vous l'indiquerez sur le rapport avec vos réflexions pour l'améliorer.\n",
        "\n",
        "Next, you have to implement the first improvements you find in the search method to get most relevant results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MecCCwzbx8qZ"
      },
      "source": [
        "## Boolean Search\n",
        "\n",
        "Thanks to the ttable library, implement a boolean search method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "id": "Sv71gdHEt5mc",
        "outputId": "13fe8baf-7d24-40ac-a360-643b8a81c287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttable\n"
      ],
      "metadata": {
        "id": "c3APVJsG1V0a",
        "outputId": "b322fe7f-1a39-41ed-e07f-fff33827ffbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ttable\n",
            "  Downloading ttable-0.6.4.tar.gz (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ttable\n",
            "  Building wheel for ttable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ttable: filename=ttable-0.6.4-cp310-cp310-linux_x86_64.whl size=212610 sha256=37a0115d0c0bb33ea36bf189478611c090d7774418497d119d5eb97fe25347ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/8d/56/f2572fdbf1ef1f8a947d7ff25ce18d9373d8e02a68f9ac8de6\n",
            "Successfully built ttable\n",
            "Installing collected packages: ttable\n",
            "Successfully installed ttable-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tt import BooleanExpression"
      ],
      "metadata": {
        "id": "V5yet0Nv1c5r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install ttable\n"
      ],
      "metadata": {
        "id": "lvgv6dFJvw9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the pickled file\n",
        "with open(os.path.join(DATA_PATH,\"inverted_index.pickle\"), \"rb\") as file:\n",
        "    loaded_dict = pickle.load(file)\n",
        "\n",
        "# Access the loaded dictionary\n",
        "\n"
      ],
      "metadata": {
        "id": "qkXOnB6i6MNN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Tokeni"
      ],
      "metadata": {
        "id": "ZxqLszuMDI2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "Nd2fFCh5DC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"inv_index_simple = {}\n",
        "for word in loaded_dict:\n",
        "  l=[]\n",
        "  tuple_list = loaded_dict[word]['inv_ind']\n",
        "  for elt in tuple_list:\n",
        "    (doc_id,_)=elt #elt = (a,b)\n",
        "    l.append(doc_id)\n",
        "  inv_index_simple[word]=l\"\"\"\n",
        "inv_index_simple['learning']\n",
        "\n"
      ],
      "metadata": {
        "id": "FARlpioJ9qzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "q5JTNdIrVdH9"
      },
      "outputs": [],
      "source": [
        "def boolean_search(query):#the query est sous la formenormale conjonctive A1 OR A2 OR A3 OR A4...\n",
        "  query_extracted = extract_words(query)\n",
        "#transforme la requête en booléen\n",
        "def transformation_query_to_boolean(query):\n",
        "    boolean_query=[]\n",
        "    for token in query.split():\n",
        "        boolean_query.append(token)\n",
        "        boolean_query.append('AND')\n",
        "    boolean_query.pop()\n",
        "    return boolean_query\n",
        "from tt import BooleanExpression\n",
        "BooleanOperator = {\"AND\", \"OR\", \"NOT\"}\n",
        "def transformation_query_to_postfixe(query):\n",
        "    b = BooleanExpression(query)\n",
        "    return b.postfix_tokens\n",
        "#merge deux posting lists selon l'opérateur\n",
        "def merge_and_postings_list(posting_term1,posting_term2):\n",
        "    result=[]\n",
        "    n = len(posting_term1)\n",
        "    m = len(posting_term2)\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < n and j <m:\n",
        "        if posting_term1[i] == posting_term2[j]:\n",
        "            result.append(posting_term1[i])\n",
        "            i = i+1\n",
        "            j = j+1\n",
        "        else:\n",
        "            if posting_term1[i] < posting_term2[j]:\n",
        "                i = i+1\n",
        "            else:\n",
        "                j=j+1\n",
        "    return result\n",
        "def merge_or_postings_list(posting_term1,posting_term2):\n",
        "    result=[]\n",
        "    n = len(posting_term1)\n",
        "    m = len(posting_term2)\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < n and j <m:\n",
        "        if posting_term1[i] == posting_term2[j]:\n",
        "            result.append(posting_term1[i])\n",
        "            i = i+1\n",
        "            j = j+1\n",
        "        else:\n",
        "            if posting_term1[i] < posting_term2[j]:\n",
        "                result.append(posting_term1[i])\n",
        "                i = i+1\n",
        "            else:\n",
        "                result.append(posting_term2[j])\n",
        "                j=j+1\n",
        "    if i <n:\n",
        "        result = result + posting_term1[i:]\n",
        "    if j <m:\n",
        "        result = result + posting_term2[j:]\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_and_not_postings_list(posting_term1,posting_term2):\n",
        "    result=[]\n",
        "    n = len(posting_term1)\n",
        "    m = len(posting_term2)\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < n and j <m:\n",
        "        if posting_term1[i] == posting_term2[j]:\n",
        "            i = i+1\n",
        "            j = j+1\n",
        "        else:\n",
        "            if posting_term1[i] < posting_term2[j]:\n",
        "                result.append(posting_term1[i])\n",
        "                i = i+1\n",
        "            else:\n",
        "                j=j+1\n",
        "    return result\n",
        "#généralise le merge selon l'opérateur\n",
        "def boolean_operator_processing_with_inverted_index(BoolOperator,posting_term1,posting_term2):\n",
        "    result=[]\n",
        "    if BoolOperator == \"AND\":\n",
        "        result.append(merge_and_postings_list(posting_term1,posting_term2))\n",
        "    elif BoolOperator==\"OR\" :\n",
        "        result.append(merge_or_postings_list(posting_term1,posting_term2))\n",
        "    elif BoolOperator == \"NOT\":\n",
        "        result.append(merge_and_not_postings_list(posting_term1,posting_term2))\n",
        "    return result\n",
        "def processing_boolean_query_with_inverted_index(booleanOperator,query, inverted_index):\n",
        "    evaluation_stack = []\n",
        "    #transformer query en liste de mots\n",
        "    \"\"\"res = word_tokenize(query)\n",
        "    Docs_id = []\n",
        "    for i in range(len(res)):\n",
        "      res[i] = lemmatizer.lemmatize(res[i])\"\"\"\n",
        "    query=extract_words(query)\n",
        "\n",
        "    for term in query:\n",
        "        if term.upper() not in booleanOperator:\n",
        "          \"\"\"print(term.upper())\n",
        "          print(inverted_index[term.upper()])\"\"\"\n",
        "          evaluation_stack.append(inverted_index[term.upper()])#on rajoute la posting list du dernier terme\n",
        "        else:\n",
        "            if term.upper() == \"NOT\":\n",
        "              operande= evaluation_stack.pop()\n",
        "              eval_prop = boolean_operator_processing_with_inverted_index(term.upper(), evaluation_stack.pop(),operande)\n",
        "              evaluation_stack.append(eval_prop[0])\n",
        "                #evaluation_stack.append(eval_prop[0])#pq 2 fois?\n",
        "            else:\n",
        "              operator = term.upper()\n",
        "              eval_prop =  boolean_operator_processing_with_inverted_index(operator, evaluation_stack.pop(),evaluation_stack.pop())\n",
        "              evaluation_stack.append(eval_prop[0])\n",
        "    return  evaluation_stack.pop()\n",
        "def compare(inverted_index,boolean_query_processed):\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processing_boolean_query_with_inverted_index(BooleanOperator,'machine learning',inv_index_simple)"
      ],
      "metadata": {
        "id": "G4oQpedE2MVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d2c3e5-ee08-46a8-e210-e4e776f1c44e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8984,\n",
              " 9221,\n",
              " 17745,\n",
              " 23857,\n",
              " 24579,\n",
              " 24875,\n",
              " 37803,\n",
              " 40086,\n",
              " 42170,\n",
              " 43241,\n",
              " 54674,\n",
              " 72523,\n",
              " 81150,\n",
              " 93013,\n",
              " 104167,\n",
              " 104329,\n",
              " 104489,\n",
              " 107475,\n",
              " 113423,\n",
              " 118409,\n",
              " 118665]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4vFldsAycpB"
      },
      "source": [
        "## Probabilistic search\n",
        "\n",
        "Implement the MIB or BM25 method of searching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCxjyrldyhUB"
      },
      "outputs": [],
      "source": [
        "def probabilistic_search(query):\n",
        "  # TODO\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9m_LFo_yog2"
      },
      "source": [
        "Compare the naive method with your improvements and the boolean and probabilistic search. (report)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arfKMWtLyyxY"
      },
      "source": [
        "# Evaluate the Search\n",
        "\n",
        "Now you implement multiple search methods and you're able to improve it. You have to define metric to compare it objectively.\n",
        "\n",
        "\n",
        "\n",
        "We ask you to implement NDCG (Normalized Discounted Cumulative Gain) from few queries we implement on a dozen of post. We already defined the values of relevance judgement in the xlsx file : . The final score will be the mean quadratic error of the queries.\n",
        "\n",
        "\n",
        "Explication for the xlsx file :\n",
        "\n",
        "We propose you a Excel file with some posts and a mesure of relevancy for the queries\n",
        "\n",
        "- First column is the post Id,\n",
        "- Columns starting by query are the queries you have to test.\n",
        "- The values in this columns are the rank of relevancy of the post in regard with the query.\n",
        "- The missing values indicates you should not take into account the post\n",
        "\n",
        "\n",
        "You will have to criticize this metric and your result in the report. Then you will have to propose some improvements. \n",
        "\n",
        "Thereafter in this week, you will have to compare your different search engines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxCcftBPagMQ"
      },
      "outputs": [],
      "source": [
        "# Read Relevancy CSV\n",
        "df_relevancy = pd.read_excel(\"/content/drive/MyDrive/TP Centrale/evaluation_search_engine_post_queries_ranking_EI_CS.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVxld-Ujy0nN"
      },
      "outputs": [],
      "source": [
        "def calculate_ndgc(query_col=\"query\", output_col=\"query_output\"):\n",
        "  # TODO\n",
        "\n",
        "  return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pistes d'amélioration\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/drive/MyDrive/EI_ST4/data' \n",
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "metadata": {
        "id": "TTp5M11W00ZE",
        "outputId": "19e1c301-cd3a-4fb1-e9b5-93f4bcf59389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts.head()\n",
        "df=posts[['Id','ViewCount','AnswerCount','CommentCount','FavoriteCount','ClosedDate']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UKZtvVfjjmZe",
        "outputId": "3ecae19f-b563-4348-a1ef-fab0a789c4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  ViewCount  AnswerCount  CommentCount  FavoriteCount  \\\n",
              "0   5      898.0          1.0             1            NaN   \n",
              "1   7      478.0          3.0             4            NaN   \n",
              "2   9        NaN          NaN             0            NaN   \n",
              "3  10        NaN          NaN             1            NaN   \n",
              "4  14     1901.0          4.0             1            NaN   \n",
              "\n",
              "                ClosedDate  \n",
              "0  2014-05-14T14:40:25.950  \n",
              "1  2014-05-14T08:40:54.950  \n",
              "2                     None  \n",
              "3                     None  \n",
              "4                     None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5143f34e-c688-48a9-a006-207e7e0bb25c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>AnswerCount</th>\n",
              "      <th>CommentCount</th>\n",
              "      <th>FavoriteCount</th>\n",
              "      <th>ClosedDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>898.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-05-14T14:40:25.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>478.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-05-14T08:40:54.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5143f34e-c688-48a9-a006-207e7e0bb25c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5143f34e-c688-48a9-a006-207e7e0bb25c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5143f34e-c688-48a9-a006-207e7e0bb25c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = 1\n",
        "c2 = 1\n",
        "df=posts[['Id','ViewCount','AnswerCount','CommentCount','FavoriteCount','ClosedDate']]\n",
        "scores=[[] for k in range (len(df))]\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "  scores[index] = [row['ViewCount']]\n",
        "  scores[index].append(  row['AnswerCount']) #mais on veut normaliser tout ça\n",
        "#on normalise les scores:\n",
        "import numpy as np\n",
        "scores=np.array(scores)\n",
        "for s in scores:\n",
        "  s[0]=s[0]/np.amax(scores[:,0])*c1\n",
        "  s[1]=s[1]/np.amax(scores[:,1])*c2\n"
      ],
      "metadata": {
        "id": "doRxXeZf1VWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listes=[[1,2],[2,4],[3,5]]\n",
        "import numpy as np\n",
        "listes=np.array(listes)\n",
        "print(listes[:,1])\n",
        "print(np.amax(listes[:,1]))"
      ],
      "metadata": {
        "id": "a1IeOgSY6oAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame()\n",
        "\n",
        "df['c1']=['Jules','Zenta','Joshua']\n",
        "df['id']=['11','12',13]"
      ],
      "metadata": {
        "id": "u86wHrgguOET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classement(list_relevant_docs,dico):\n",
        "  pass"
      ],
      "metadata": {
        "id": "-XBaCDbOm7qa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}